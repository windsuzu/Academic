# Beyond Classical Search

## Local Search Algorithms and Optimization Algorithms

å‰å¹¾ç« çš„ Search algorithm åœ¨æ‰¾è§£ç­”æ™‚

é †ä¾¿æŠŠç¶“éä¹Ÿæ‰¾äº†å‡ºä¾† \(e.g., path to goal\)

ä½†å…¶å¯¦å¾ˆå¤šå•é¡Œåªè¦æ±‚è§£ç­”è€Œå·² \(e.g., 8-queens problem\)

* é€™ç¨®ç›´æ¥æ±‚è§£çš„ç®—æ³•ç¨±ä½œ **Local Search** Algorithm
  * æ¯å€‹ operation åªå°‡ single current node ç§»å‹•åˆ°é„°å±…
  * low memory
  * å¯ä»¥åœ¨ infinite state spaces æ‰¾åˆ° reasonable solutions
  * ä»–é©åˆåˆ©ç”¨ **objective function** ä¾†è§£æ±º **optimization problems**

![](../.gitbook/assets/state_space_1d%20%281%29.png)

* Local Search çš„ç›®æ¨™æ˜¯æ‰¾åˆ° Global maximum \(ä¹Ÿå°±æ˜¯ best solution\)
* ä¸‹é¢ä»‹ç´¹ç¬¬ä¸€å€‹ local search algorithm : hill climbing 

### Hill Climbing Search

* æœƒåœ¨ loop ä¸­ä¸æ–·æ‰¾å°‹å¯ä»¥å¾€ä¸Šèµ°çš„æ–¹å‘
  * ç›´åˆ°æ‰¾åˆ° **peak \(no neighbor has a higher value\)** æ‰åœæ­¢
* å› ç‚ºåªè§€å¯Ÿ current state çš„é„°å±…ï¼Œä¸æœƒè§€å¯Ÿå…¨å±€
  * æ‰€ä»¥åªéœ€ä¿å­˜ current node çš„ objective function value
    * ä¸éœ€è¦ç”¨åˆ° search tree structure
* åˆç¨±ä½œ **Greedy local search** \(æ•ˆèƒ½é‚„ä¸éŒ¯\)
* ä½†æ¼”ç®—æ³•æœƒå› ç‚ºä¸€äº›åŸå› è€Œå¡ä½ :
  * Local maxima
  * Ridges
  * Plateaux or shoulder

![](../.gitbook/assets/hill_climbing_algorithm.png)

#### Example : 8-queens problem

* Successors of a state : æ”¾ä¸‹ queen ä¹‹å¾Œçš„æ‰€æœ‰çš„å¯èƒ½æ€§
* Heuristic cost function \(h\) : æœ‰å¹¾å° queens æœƒäº’ç›¸æ”»æ“Š
* ç•¶ best h æœ‰æ•¸å€‹æ™‚ï¼Œæœƒéš¨æ©Ÿé¸å–

![](../.gitbook/assets/hill_climbing_8_queens%20%281%29.png)

* 8-queens å…±æœ‰ 8^8 states \(17 millions\)
* è‹¥å¾ˆ greedy æ¯æ¬¡çš†é¸æœ€é™¡çš„è·¯å¾€ä¸Šèµ°
  * æœ‰ 86% æœƒå¡ä½
    * ä½†åªéœ€èŠ± 3 æ­¥å°±æœƒå¡ä½
  * åªæœ‰ 14% æœƒæ‰¾åˆ°è§£
    * ä½†åªéœ€èŠ± 4 æ­¥æ‰¾åˆ°è§£
* è‹¥æ˜¯ç¹¼çºŒèµ°ï¼Œå¸Œæœ›èµ°åˆ°çš„åªæ˜¯ä¸€å€‹ plateau
  * æœ‰ 94% å¯ä»¥æ‰¾åˆ°è§£
    * ä½†è¦èŠ± 21 æ­¥
  * è€Œå¤±èª¤çš„è©±è¦ç­‰åˆ° 64 æ­¥æ‰æœƒçŸ¥é“

#### Mutation

* **Stocastic hill climbing**
  * åœ¨é¸æ“‡ uphill move æ™‚ï¼Œæœƒ random select ä¸€å€‹åšç‚ºä¸‹ä¸€å€‹ move
* **First-choice hill climbing**
  * å¾ random è£¡é¢é–‹å§‹æ‰¾ï¼Œæ‰¾åˆ°ç¬¬ä¸€å€‹æ¯” current state å¥½çš„ move å°±ç§»å‹•
* **Random-restart hill climbing**
  * å¤±æ•—äº†å°±è‡ªå‹•é‡ä¾†ï¼Œç›´åˆ°åˆ°é” goal state ç‚ºæ­¢

### Simulated Annealing

* Annealing \(å†¶é‡‘é€€ç«\)
  * æ˜¯æŠŠé‡‘å±¬åŠ ç†±è‡³æœ€é«˜é»å¾Œï¼Œæ…¢æ…¢é™æº«çš„æ‰‹æ³•
* Simulated Annealing
  * ä¸€æ¨£ random é¸æ“‡
    * åªè¦æ¯” current state å¥½å°±æ°¸é  accept
    * å°±ç®—æ¯” current state å·®ä¹Ÿæœƒæœ‰**ä¸€å®šæ©Ÿç‡** accept
      * ä½†æ˜¯**æ©Ÿç‡**æœƒéš¨è‘—æ­¥æ•¸çš„å¢åŠ è€Œ decrease \(å°±åƒé€€ç«\)
      * With teperature T goes down
        * It becomes unlikely to accept badness

![](../.gitbook/assets/simulated_annealing.png)

### Local Beam Search

* æœƒä¸€æ¬¡ track **k** å€‹ states \(åˆ¥çš„ç®—æ³•åªæœ‰ä¸€å€‹\)
* initialize : k ramdom states
* Every step : all k states generate k^2 states
* å¦‚æœæŸä¸€å€‹ state ç‚º goal state å°±ä¸­æ­¢ç®—æ³•
* Local beam search çœ‹èµ·ä¾†å°±åªæ˜¯ k å€‹ states è¢«å¹³è¡Œæ“ä½œ
* ä½†å…¶å¯¦é€™ k å€‹ states æ˜¯æœƒäº’ç›¸å½±éŸ¿, äº’ç›¸å‚³é€è³‡æ–™çš„
* è®Šå½¢ç‚º **Stochastic beam search**
  * æ˜¯ random ç”¢ç”Ÿ k successors

### Genetic Algorithm

* æ˜¯ Stochastic beam search çš„è®Šå½¢
* æœƒæ‰¾åˆ°å…©å€‹ parent states ä¾†ç”¢ç”Ÿæ–°çš„ state

![](../.gitbook/assets/genetic_algorithms_graph.png)

* Population : k ramdomly begin states
* Individual : each state
  * ç”¨ strings æˆ–æ˜¯ 0/1 ä¾†è¡¨é”
* ç”¢ç”Ÿ successor æ–¹æ³• : 1. æœƒå°æ¯å€‹ states æ‰“åˆ†æ•¸ \(**fitness** score\) 2. å¾åˆ†æ•¸çµ¦å®šæ¯ä¸€å€‹ states è¢«æŒ‘é¸çš„æ©Ÿç‡ 3. å¾æ©Ÿç‡é¸æ“‡å…©å€‹ states ä½œç‚º parent pair 4. æ¯å€‹ pair é€²è¡Œ **crossover** èåˆ 5. æœ€å¾Œå†å°‡çµ„åˆå¥½çš„ state é€²è¡Œ **mutation**
* ä¸‹é¢æ˜¯ crossover in 8-queens problem ![](../.gitbook/assets/genetic_algorithms_crossover%20%281%29.png)

## Local Search in Continuous Spaces

* å•é¡Œä¾‹å­
  * å®šç¾©ä¸‰å€‹æ©Ÿå ´çš„ coordinates \(x, y\)
  * æ¯å€‹åŸå¸‚åˆ°å…¶ä¸­ä¸‰å€‹æ©Ÿå ´çš„è·é›¢éƒ½è¦æœ€è¿‘
  * æœ‰ $$(x_1, y_1), (x_2, y_2), (x_3, y_3)$$ å…­å€‹è®Šæ•¸ \(6-dimensional space\)
  * å¯ä»¥ **discretize** problemï¼Œåˆ©ç”¨ $$\delta$$ limitation è®“å•é¡Œæ¯æ¬¡åªç”¢ç”Ÿ 12 successors
  * ä»¤ $$C_i$$ ç‚ºè·Ÿ airport $$i$$ æœ€è¿‘çš„ citiesï¼Œè€Œ objective function ç‚º

    $$
    f(x_1, y_1, x_2, y_2, x_3, y_3) = \sum_{i=1}^3\sum_{c\in C_i}(x_i-x_c)^2+(y_i-y_c)^2
    $$

  * é€šå¸¸æœƒä½¿ç”¨ gradient æ–¹å¼æ‰¾æœ€ä½³è§£
  * ä¸€å€‹ objective function çš„ gradient æœƒç”¨ $$\nabla f$$ è¡¨ç¤º

    $$
    \nabla f = \left(\frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial y_1}, \frac{\partial f}{\partial x_2}, \frac{\partial f}{\partial y_2}, \frac{\partial f}{\partial x_3}, \frac{\partial f}{\partial y_3}\right)
    $$

  * ä¾‹å¦‚ $$\frac{\partial f}{\partial x_1} = 2 \sum_{c\in C_1} (x_i - x_c)$$
  * ç›®æ¨™å°±æ˜¯è¦æ‰¾åˆ° $$\nabla f = 0$$ \(æ–œåº¦æ­¸é›¶ä»£è¡¨æ‰¾åˆ°æœ€ä½³è§£\)
  * æ›´ formal çš„ gradient algorithm å¯ä»¥å¯«ç‚º $$x \leftarrow x + \alpha \nabla f(x)$$
    * $$\alpha$$ ç‚º step size \(learning rate\)
* $$\alpha$$ çš„æŒ‘é¸å¤ªå°è·Ÿå¤ªå¤§éƒ½ä¸å¥½
  * å¯ä»¥åˆ©ç”¨ line search algorithms ä¾†æŒ‘é¸é©åˆçš„ $$\alpha$$ å€¼
  * æœ€æœ‰åçš„ç®—æ³•æ˜¯ **Newton-Raphson** method
* Local search åœ¨ continuous space ä¸€æ¨£æœƒæœ‰ local maxima ç­‰å•é¡Œ
  * å¯ä»¥ä½¿ç”¨ restarts, annealing ä¾†å¹«åŠ©
* é€™é¡ **constraint optimization** æœ€æœ‰åçš„æ˜¯ **linear programming** \(convex problem\)

## Searching with Nondeterministic Actions

* ä¹‹å‰çš„å•é¡Œéƒ½æ˜¯ deterministic problem \(actions æœƒç”¢ç”Ÿæ–°çš„å›ºå®š states\)
* Nondeterministic problem å‰‡æ˜¯ actions ä¸ä¸€å®šç”¢ç”Ÿå¸¸ç†çš„æ–° states
* ç”¨æƒåœ°æ©Ÿå™¨äººçš„å•é¡Œèˆ‰ä¾‹
  * Deterministic =&gt; state 1 å¸å®Œä¸€å®šè·‘åˆ° state 5
  * Nondeterministic =&gt; state 1 å¸å®Œå¯èƒ½è·‘åˆ° state 1, 5, 7 \(å¸åŠ›ç•°å¸¸\)

![](../.gitbook/assets/vacuum_world%20%281%29.png)

* å› ç‚º nondeterministic ä¸ä¸€å®šæœƒæœ‰å›ºå®šçš„ actions ä¾†è§£æ±ºå•é¡Œ
* result è®Šç‚º results
* single state è®Šç‚º set of possible states
* æ‰€ä»¥å¿…é ˆæŠŠ contingency plan è€ƒæ…®é€²å» \(å¦‚æœ suck å¾ŒæˆåŠŸè®Šç‚º 5 å†ç¹¼çºŒè¡Œå‹•\)
* ä¸–ç•Œä¸Šçš„æ—¥å¸¸å•é¡Œé€šå¸¸éƒ½æ˜¯é€™ç¨® contingency problems
* é€šå¸¸è§£æ±ºçš„ solution æœƒåŒ…å« nested **if-then-else**

  ```text
  [Suck, if State = 5 then [Right, Suck] else []]
  ```

* æˆ‘å€‘æœƒç”¨ AND-OR search trees ä¾†è¡¨é” nondeterministic actions
  * OR nodes ç”¨ä¾†é€£æ¥åˆ°æ—¢å®šç‹€æ³ \(sequential states\)
  * AND nodes ç”¨ä¾†é€£æ¥åˆ°ä¸ç¢ºå®šç‹€æ³ \(non-deterministic\)
  * æ¯å€‹ leaf éƒ½æ˜¯ä¸€å€‹ goal

![](../.gitbook/assets/and_or_tree.png)

* Nondeterministic é‚„å¯ä»¥æœ‰ cyclic solution
  * ä¸å†æ˜¯ tree çš„æ¶æ§‹
  * ä¾‹å¦‚æƒåœ°æ©Ÿå™¨äººçš„ç§»å‹•åŠŸèƒ½å£æ‰
  * å¯èƒ½å¾€å³ç§»ä¸æ–·å¤±æ•—ï¼Œç„¶å¾Œä¸æ–·é‡è¤‡å³ç§»
  * æˆ‘å€‘å¯ä»¥åŠ å…¥ label ä¾†è¡¨ç¤ºä¸€å€‹ plan æ–¹ä¾¿åœ¨é‡è¤‡æ™‚å‘¼å«

    ```text
    [Suck, L1 : Right, if state = 5 then L1 else Suck]
    ```

## Searching with Partial Observations

### Searching with no observation \(sensorless problem\)

* agent ç„¡æ³•æ„ŸçŸ¥ç’°å¢ƒï¼Œä½† agent çŸ¥é“è©²åšå“ªäº›äº‹æƒ…
* agent æœƒæŠŠæ‰€æœ‰è©²åšçš„äº‹æƒ…åšå¥½ï¼Œç”¨ **coerce** æ–¹å¼é”æˆ goal state
* **Belief states** : åŒ…å«æ‰€æœ‰å¯èƒ½çš„ physical states
  * è‹¥æœ‰ N å€‹ statesï¼Œé‚£ sensorless problem å¯ä»¥æé«˜åˆ° $$2^N$$ states
* **Initial states** : all possible states in the problem
* **Actions** : å¦‚æœ actions éƒ½ä¸æœƒç™¼ç”Ÿä»€éº¼åš´é‡å¾Œæœï¼Œé‚£éº¼æœƒå°‡ actions union çµ„åˆ
  * å¦‚æœæŸå€‹ action æœƒé€ æˆåš´é‡å¾Œæœï¼Œé‚£éº¼ actions æœ€å¥½ä½¿ç”¨ intersect çµ„åˆ
* **Transition model** : ç”Ÿæˆæ–°çš„ belief states çš„ç¨‹åºæˆ‘å€‘ç¨±ç‚º **prediction step**

  $$
  b' = \text{PREDICT}_p(b,a)
  $$

![](../.gitbook/assets/sensorless_vacuum.png)

* **Goal test** : Agent å¯èƒ½æœƒä¸å°å¿ƒå°±è§¸ç™¼ goal çš„æ¢ä»¶ï¼Œä½†è‡ªå·±å»ä¸çŸ¥é“
* **Path cost** : ç›¸åŒçš„ action åœ¨ä¸åŒçš„ states é€²è¡Œæ™‚å¯èƒ½æœƒä¸åŒ
* ç¾åœ¨æˆ‘å€‘å¯ä»¥ formulate automatic construction
* å†æ‡‰ç”¨ä¹‹å‰çš„ search algorithms

![](../.gitbook/assets/automatic_construction.png)

### Solving partially observable problems

* ä¸€å€‹ partially observable agent èˆ‡ä¸€èˆ¬çš„ agent æœ‰å…©é»ä¸åŒ
* solution å°‡ä¸å†æ˜¯ sequential è€Œæ˜¯ conditional
* éœ€è¦ç¶­è­·æ¯å€‹ action éå¾Œçš„ belief states

![](../.gitbook/assets/partial_observation%20%281%29.png)

* ä¸Šåœ–åˆæ˜¯ä¸€å€‹å¹¼ç¨šåœ’ç‰ˆçš„æƒåœ°æ©Ÿå™¨äºº
* æ¯æ¬¡æƒåœ°å®Œå¯èƒ½æœƒæœ‰å°æœ‹å‹åˆäº‚ä¸Ÿåƒåœ¾

![](../.gitbook/assets/robot_predict%20%281%29.png)

* ä¸Šåœ–æ˜¯å¦å¤–ä¸€ç¨® robot position å•é¡Œ
* æˆ‘å€‘è¦å¾çµ¦å®šçš„ robot ç›®å‰éšœç¤™ç‰©ï¼Œä¾†ä¸€æ­¥æ­¥åˆ¤æ–· robot çš„ä½ç½®

## Online Searching Agents with Unknown Environments

* ä»¥ä¸Šæˆ‘å€‘è¬›çš„éƒ½æ˜¯ **Offline search**
  * åœ¨é‚„æ²’è§£æ±ºå•é¡Œå°±å·²ç¶“çŸ¥é“æ‰€æœ‰çœŸå¯¦ä¸–ç•Œæœƒç™¼ç”Ÿçš„äº‹æƒ…
* **Online search** å‰‡æ˜¯æœƒåœ¨æ¥æ”¶ action å¾Œçš„ç‹€æ³ä¾†æ±ºå®šä¸‹ä¸€å€‹ action
  * æœ€è‘—åçš„ä¾‹å­å°±æ˜¯ä»¥èµ°è·¯æ©Ÿå™¨äººä¾†å»ºç«‹ä¸€å€‹å¹³é¢çš„ 3D åœ°åœ–
* Online search ä¸€æ¨£éœ€è€ƒæ…® :
  * **Actions** : åœ¨ state s å¯ä»¥ä½¿ç”¨çš„ actions
  * **Step cost** : åªæœ‰åœ¨å®Œæ•´åšå®Œ action å¾Œæ‰æœƒçŸ¥é“
  * **Goal test** : Cannot determine RESULT\(s,a\) except by actually being in s and doing a.
  * **Competitive ratio** : é¡ä¼¼æ–¼ actual shortest pathï¼Œè¶Šå°è¶Šå¥½
* DFS å’Œ hill-climbing ç®—æ³•è¼ƒé©åˆç”¨æ–¼ online search

